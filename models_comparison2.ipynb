{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ed4b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3693d6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"StockPred\").getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# -----------------------\n",
    "# Load CSV\n",
    "# -----------------------\n",
    "df = pd.read_csv(\"D:\\\\stock\\\\Market.csv\")\n",
    "\n",
    "# Drop non-numeric columns (e.g., Date)\n",
    "df = df.drop(columns=[\"Date\"], errors=\"ignore\")\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale all numeric columns between 0 and 1\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(df.drop(columns=[\"Close\"]).values)\n",
    "y = scaler_y.fit_transform(df[[\"Close\"]].values)  # keep 2D for scaler\n",
    "\n",
    "\n",
    "dataset = TensorDataset(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f500d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(StockNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e31ce5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        for xb, yb in dataloader:\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_preds.append(preds.detach())\n",
    "            all_targets.append(yb.detach())\n",
    "\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "        mae = mean_absolute_error(all_targets, all_preds)\n",
    "        r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6847bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model 1: Divide Epochs ---\n",
      "\n",
      "Block 1\n",
      "Epoch 1/10, Loss: 384261832048640.0000, MAE: 438362.5938, R²: -718550.9375\n",
      "Epoch 2/10, Loss: 11700794.0000, MAE: 151970.2188, R²: -200255.0781\n",
      "Epoch 3/10, Loss: 20803096576.0000, MAE: 46160.4219, R²: -8114.5039\n",
      "Epoch 4/10, Loss: 59223444.0000, MAE: 29275.3242, R²: -3975.9580\n",
      "Epoch 5/10, Loss: 25637284.0000, MAE: 4621.8945, R²: -4.7245\n",
      "Epoch 6/10, Loss: 20301504.0000, MAE: 4684.1943, R²: -2.9557\n",
      "Epoch 7/10, Loss: 72180640.0000, MAE: 3720.4336, R²: 0.3764\n",
      "Epoch 8/10, Loss: 5488175.0000, MAE: 3690.5142, R²: 0.3841\n",
      "Epoch 9/10, Loss: 160804992.0000, MAE: 4023.4597, R²: -0.3683\n",
      "Epoch 10/10, Loss: 35582104.0000, MAE: 4065.6819, R²: -6.2156\n",
      "\n",
      "Block 2\n",
      "Epoch 1/10, Loss: 45536612.0000, MAE: 4006.3345, R²: -2.3984\n",
      "Epoch 2/10, Loss: 30588850.0000, MAE: 4188.7954, R²: -0.7309\n",
      "Epoch 3/10, Loss: 28720232.0000, MAE: 3808.0859, R²: -0.2549\n",
      "Epoch 4/10, Loss: 3524144.2500, MAE: 3863.5383, R²: 0.3572\n",
      "Epoch 5/10, Loss: 19921358.0000, MAE: 3797.4646, R²: 0.1950\n",
      "Epoch 6/10, Loss: 73462.0156, MAE: 3937.5293, R²: 0.3611\n",
      "Epoch 7/10, Loss: 26893726.0000, MAE: 4043.0400, R²: -4.4084\n",
      "Epoch 8/10, Loss: 22034130.0000, MAE: 4150.9961, R²: -1.4714\n",
      "Epoch 9/10, Loss: 23093534.0000, MAE: 4900.9331, R²: -311.2077\n",
      "Epoch 10/10, Loss: 31107986.0000, MAE: 4574.3765, R²: -125.2819\n",
      "\n",
      "Block 3\n",
      "Epoch 1/10, Loss: 18301150.0000, MAE: 4194.9336, R²: -0.3776\n",
      "Epoch 2/10, Loss: 7669006.0000, MAE: 3855.2129, R²: 0.3735\n",
      "Epoch 3/10, Loss: 123019352.0000, MAE: 3792.7803, R²: 0.3819\n",
      "Epoch 4/10, Loss: 48653408.0000, MAE: 4224.0562, R²: -43.1498\n",
      "Epoch 5/10, Loss: 65388416.0000, MAE: 4064.3613, R²: -17.7799\n",
      "Epoch 6/10, Loss: 3200164.0000, MAE: 3952.6982, R²: -1.1817\n",
      "Epoch 7/10, Loss: 56791396.0000, MAE: 4226.2559, R²: -18.3760\n",
      "Epoch 8/10, Loss: 4875154.0000, MAE: 4033.0723, R²: -0.3738\n",
      "Epoch 9/10, Loss: 21539830.0000, MAE: 4148.4834, R²: -6.4422\n",
      "Epoch 10/10, Loss: 22338850.0000, MAE: 4036.6758, R²: -15.2449\n",
      "\n",
      "Block 4\n",
      "Epoch 1/10, Loss: 24661406.0000, MAE: 3864.8572, R²: 0.3735\n",
      "Epoch 2/10, Loss: 16364510.0000, MAE: 3863.0405, R²: 0.3082\n",
      "Epoch 3/10, Loss: 79655824.0000, MAE: 4248.3975, R²: -2.0962\n",
      "Epoch 4/10, Loss: 1710486.8750, MAE: 3980.5205, R²: 0.2285\n",
      "Epoch 5/10, Loss: 14397712.0000, MAE: 4448.9360, R²: -19.7071\n",
      "Epoch 6/10, Loss: 13407519.0000, MAE: 3974.1777, R²: -0.2383\n",
      "Epoch 7/10, Loss: 87360864.0000, MAE: 3985.8293, R²: 0.3663\n",
      "Epoch 8/10, Loss: 71435744.0000, MAE: 4153.2505, R²: 0.3291\n",
      "Epoch 9/10, Loss: 57393184.0000, MAE: 4277.1567, R²: -5.6612\n",
      "Epoch 10/10, Loss: 67021348.0000, MAE: 4665.9907, R²: -108.3704\n",
      "\n",
      "Block 5\n",
      "Epoch 1/10, Loss: 51470416.0000, MAE: 4044.8262, R²: 0.3584\n",
      "Epoch 2/10, Loss: 53847756.0000, MAE: 4542.0010, R²: -90.7370\n",
      "Epoch 3/10, Loss: 45700992.0000, MAE: 4108.0566, R²: -2.7449\n",
      "Epoch 4/10, Loss: 44430708.0000, MAE: 3960.1907, R²: 0.2889\n",
      "Epoch 5/10, Loss: 142917904.0000, MAE: 4133.7598, R²: -14.8519\n",
      "Epoch 6/10, Loss: 54424880.0000, MAE: 3997.9207, R²: 0.3653\n",
      "Epoch 7/10, Loss: 62342992.0000, MAE: 3837.3970, R²: 0.3743\n",
      "Epoch 8/10, Loss: 12851582.0000, MAE: 4022.5845, R²: 0.3469\n",
      "Epoch 9/10, Loss: 88477096.0000, MAE: 4019.7163, R²: 0.3615\n",
      "Epoch 10/10, Loss: 40181232.0000, MAE: 4570.0479, R²: -27.2144\n",
      "\n",
      "Block 6\n",
      "Epoch 1/10, Loss: 25531516.0000, MAE: 4238.8501, R²: 0.3378\n",
      "Epoch 2/10, Loss: 73956848.0000, MAE: 4137.1543, R²: 0.3457\n",
      "Epoch 3/10, Loss: 16969300.0000, MAE: 4146.4170, R²: 0.3464\n",
      "Epoch 4/10, Loss: 103195136.0000, MAE: 4136.9204, R²: -19.0583\n",
      "Epoch 5/10, Loss: 89129744.0000, MAE: 4646.0420, R²: -8.3284\n",
      "Epoch 6/10, Loss: 33204348.0000, MAE: 4190.1631, R²: 0.3319\n",
      "Epoch 7/10, Loss: 52386956.0000, MAE: 3914.8123, R²: 0.3740\n",
      "Epoch 8/10, Loss: 100910672.0000, MAE: 3848.7412, R²: 0.3768\n",
      "Epoch 9/10, Loss: 33988720.0000, MAE: 4543.1626, R²: -76.3437\n",
      "Epoch 10/10, Loss: 24294848.0000, MAE: 3771.4788, R²: 0.3873\n",
      "\n",
      "Block 7\n",
      "Epoch 1/10, Loss: 45470472.0000, MAE: 4111.2456, R²: -57.7867\n",
      "Epoch 2/10, Loss: 25097640.0000, MAE: 4039.6201, R²: 0.3211\n",
      "Epoch 3/10, Loss: 48190832.0000, MAE: 5372.0386, R²: -488.7256\n",
      "Epoch 4/10, Loss: 34701660.0000, MAE: 4273.5630, R²: 0.3454\n",
      "Epoch 5/10, Loss: 54610000.0000, MAE: 4181.1123, R²: 0.3519\n",
      "Epoch 6/10, Loss: 61969200.0000, MAE: 4335.4429, R²: -21.9178\n",
      "Epoch 7/10, Loss: 145536512.0000, MAE: 3970.7864, R²: 0.3705\n",
      "Epoch 8/10, Loss: 45785420.0000, MAE: 3881.2678, R²: -0.2496\n",
      "Epoch 9/10, Loss: 28969072.0000, MAE: 4019.9231, R²: 0.3628\n",
      "Epoch 10/10, Loss: 86870408.0000, MAE: 4474.3901, R²: -84.3439\n",
      "\n",
      "Block 8\n",
      "Epoch 1/10, Loss: 34763508.0000, MAE: 4090.8823, R²: 0.3530\n",
      "Epoch 2/10, Loss: 9757508.0000, MAE: 4142.4136, R²: 0.3476\n",
      "Epoch 3/10, Loss: 17405826.0000, MAE: 3890.3804, R²: 0.3763\n",
      "Epoch 4/10, Loss: 25228904.0000, MAE: 4274.1992, R²: -2.9964\n",
      "Epoch 5/10, Loss: 94225368.0000, MAE: 4124.1470, R²: 0.3563\n",
      "Epoch 6/10, Loss: 35527588.0000, MAE: 4103.2241, R²: 0.3103\n",
      "Epoch 7/10, Loss: 87806344.0000, MAE: 4041.2754, R²: 0.3705\n",
      "Epoch 8/10, Loss: 18437424.0000, MAE: 4824.5513, R²: -401.9538\n",
      "Epoch 9/10, Loss: 28838520.0000, MAE: 4073.0918, R²: -2.2421\n",
      "Epoch 10/10, Loss: 81270976.0000, MAE: 4062.5222, R²: 0.3636\n",
      "\n",
      "Block 9\n",
      "Epoch 1/10, Loss: 23180032.0000, MAE: 4067.2363, R²: 0.3611\n",
      "Epoch 2/10, Loss: 14284089.0000, MAE: 3973.1245, R²: 0.3735\n",
      "Epoch 3/10, Loss: 8366268.5000, MAE: 3904.7629, R²: 0.3794\n",
      "Epoch 4/10, Loss: 22997674.0000, MAE: 4059.1804, R²: -2.0550\n",
      "Epoch 5/10, Loss: 47811820.0000, MAE: 4229.2285, R²: -6.4502\n",
      "Epoch 6/10, Loss: 16751168.0000, MAE: 4100.4941, R²: 0.3582\n",
      "Epoch 7/10, Loss: 30742664.0000, MAE: 4081.1104, R²: 0.3593\n",
      "Epoch 8/10, Loss: 6833056.5000, MAE: 4115.6709, R²: 0.3581\n",
      "Epoch 9/10, Loss: 64242896.0000, MAE: 4095.4514, R²: 0.3593\n",
      "Epoch 10/10, Loss: 1604758.2500, MAE: 4056.3350, R²: 0.3633\n",
      "\n",
      "Block 10\n",
      "Epoch 1/10, Loss: 6681768.5000, MAE: 5771.6592, R²: -1265.3395\n",
      "Epoch 2/10, Loss: 60382192.0000, MAE: 4104.0420, R²: 0.3729\n",
      "Epoch 3/10, Loss: 37382224.0000, MAE: 4070.4141, R²: 0.3745\n",
      "Epoch 4/10, Loss: 14396191.0000, MAE: 4030.7856, R²: 0.3795\n",
      "Epoch 5/10, Loss: 56019536.0000, MAE: 3972.3870, R²: 0.3851\n",
      "Epoch 6/10, Loss: 48033956.0000, MAE: 4001.4258, R²: -0.8561\n",
      "Epoch 7/10, Loss: 41976208.0000, MAE: 4011.8076, R²: 0.3786\n",
      "Epoch 8/10, Loss: 89947064.0000, MAE: 4825.5625, R²: -25.2401\n",
      "Epoch 9/10, Loss: 55441724.0000, MAE: 4116.7563, R²: 0.3584\n",
      "Epoch 10/10, Loss: 40159540.0000, MAE: 4069.5229, R²: 0.3630\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "print(\"\\n--- Model 1: Divide Epochs ---\")\n",
    "model1 = StockNN(input_dim=X.shape[1])\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dataloader_full = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for block in range(10):   # 10 blocks × 10 epochs = 100 epochs\n",
    "    print(f\"\\nBlock {block+1}\")\n",
    "    train_model(model1, dataloader_full, optimizer1, criterion, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8a27b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset 1\n",
      "Epoch 1/10, Loss: 3163849.5000, MAE: 387213.8438, R²: -2033783.2500\n",
      "Epoch 2/10, Loss: 27373920.0000, MAE: 1654.6405, R²: -2.8943\n",
      "Epoch 3/10, Loss: 10425511.0000, MAE: 1081.1443, R²: -0.1835\n",
      "Epoch 4/10, Loss: 572826.2500, MAE: 1358.3533, R²: -1.9950\n",
      "Epoch 5/10, Loss: 328453248.0000, MAE: 2091.5535, R²: -5.6224\n",
      "Epoch 6/10, Loss: 11435121.0000, MAE: 4641.8291, R²: -69.6009\n",
      "Epoch 7/10, Loss: 35415818240.0000, MAE: 79061.9844, R²: -24697.9609\n",
      "Epoch 8/10, Loss: 38090.3750, MAE: 553890.4375, R²: -1344335.5000\n",
      "Epoch 9/10, Loss: 6130262.0000, MAE: 852.4103, R²: 0.3952\n",
      "Epoch 10/10, Loss: 1772995.3750, MAE: 1071.1125, R²: -0.1834\n",
      "\n",
      "Subset 2\n",
      "Epoch 1/10, Loss: 783524.1250, MAE: 1206.9003, R²: 0.7137\n",
      "Epoch 2/10, Loss: 4464794.0000, MAE: 1610.5055, R²: 0.3622\n",
      "Epoch 3/10, Loss: 5717619.5000, MAE: 1529.2286, R²: 0.4523\n",
      "Epoch 4/10, Loss: 6106918.0000, MAE: 1434.5635, R²: 0.5845\n",
      "Epoch 5/10, Loss: 12999557.0000, MAE: 1834.1028, R²: 0.2898\n",
      "Epoch 6/10, Loss: 113191888.0000, MAE: 4680.4556, R²: -7.9561\n",
      "Epoch 7/10, Loss: 276173376.0000, MAE: 34519.6719, R²: -1375.1165\n",
      "Epoch 8/10, Loss: 22265608.0000, MAE: 124026.7969, R²: -9041.3125\n",
      "Epoch 9/10, Loss: 146211904.0000, MAE: 136093.8594, R²: -7218.9419\n",
      "Epoch 10/10, Loss: 784400318464.0000, MAE: 318938.7188, R²: -25772.4375\n",
      "\n",
      "Subset 3\n",
      "Epoch 1/10, Loss: 151990624.0000, MAE: 48171.9492, R²: -677.8265\n",
      "Epoch 2/10, Loss: 154175248.0000, MAE: 6838.9277, R²: -1.1347\n",
      "Epoch 3/10, Loss: 65586032.0000, MAE: 7550.0215, R²: -2.0394\n",
      "Epoch 4/10, Loss: 346556128.0000, MAE: 7959.3433, R²: -2.7438\n",
      "Epoch 5/10, Loss: 20620003328.0000, MAE: 81843.5000, R²: -2567.1313\n",
      "Epoch 6/10, Loss: 126555728.0000, MAE: 100975.5156, R²: -1706.7139\n",
      "Epoch 7/10, Loss: 49660744.0000, MAE: 23795.5312, R²: -44.8327\n",
      "Epoch 8/10, Loss: 15136287744.0000, MAE: 74678.1094, R²: -571.8550\n",
      "Epoch 9/10, Loss: 7290028032.0000, MAE: 87050.0625, R²: -781.8311\n",
      "Epoch 10/10, Loss: 419191264.0000, MAE: 79240.5156, R²: -583.9803\n",
      "\n",
      "Subset 4\n",
      "Epoch 1/10, Loss: 111686472.0000, MAE: 29894.4375, R²: -424.9479\n",
      "Epoch 2/10, Loss: 1107372.8750, MAE: 3533.8765, R²: -0.3308\n",
      "Epoch 3/10, Loss: 23412110.0000, MAE: 27053.3438, R²: -159.0315\n",
      "Epoch 4/10, Loss: 249779440.0000, MAE: 82659.2500, R²: -2263.5728\n",
      "Epoch 5/10, Loss: 6275971.0000, MAE: 10767.4404, R²: -25.3153\n",
      "Epoch 6/10, Loss: 51462656.0000, MAE: 16384.1602, R²: -51.2686\n",
      "Epoch 7/10, Loss: 30929410048.0000, MAE: 9124.8203, R²: -24.9634\n",
      "Epoch 8/10, Loss: 16537834.0000, MAE: 71515.9531, R²: -2197.1860\n",
      "Epoch 9/10, Loss: 3801311.5000, MAE: 4492.1914, R²: -2.5872\n",
      "Epoch 10/10, Loss: 21136718.0000, MAE: 12142.4580, R²: -39.8889\n",
      "\n",
      "Subset 5\n",
      "Epoch 1/10, Loss: 30950924.0000, MAE: 1397745.7500, R²: -2716220.2500\n",
      "Epoch 2/10, Loss: 7799059.0000, MAE: 2520.9128, R²: 0.1981\n",
      "Epoch 3/10, Loss: 6564575.5000, MAE: 2930.8108, R²: -0.0834\n",
      "Epoch 4/10, Loss: 39298756.0000, MAE: 3346.3442, R²: -0.4700\n",
      "Epoch 5/10, Loss: 22435038.0000, MAE: 4025.2571, R²: -1.3831\n",
      "Epoch 6/10, Loss: 36520092.0000, MAE: 5457.5483, R²: -4.8455\n",
      "Epoch 7/10, Loss: 1660708992.0000, MAE: 12835.2041, R²: -47.8718\n",
      "Epoch 8/10, Loss: 216510742528.0000, MAE: 489871.5938, R²: -151022.6562\n",
      "Epoch 9/10, Loss: 7317876.5000, MAE: 20304.8340, R²: -142.7402\n",
      "Epoch 10/10, Loss: 114545090560.0000, MAE: 36788.0664, R²: -919.9338\n",
      "\n",
      "Subset 6\n",
      "Epoch 1/10, Loss: 843800704.0000, MAE: 12680.9600, R²: -64.1998\n",
      "Epoch 2/10, Loss: 65846548.0000, MAE: 10887.7715, R²: -47.1974\n",
      "Epoch 3/10, Loss: 564074752.0000, MAE: 8841.0312, R²: -30.8282\n",
      "Epoch 4/10, Loss: 62380032.0000, MAE: 6872.0420, R²: -18.4221\n",
      "Epoch 5/10, Loss: 42683432.0000, MAE: 4982.7603, R²: -9.7944\n",
      "Epoch 6/10, Loss: 6708662.0000, MAE: 3473.3892, R²: -4.4011\n",
      "Epoch 7/10, Loss: 8611750.0000, MAE: 2316.4622, R²: -1.4139\n",
      "Epoch 8/10, Loss: 20562906.0000, MAE: 1530.2515, R²: -0.1049\n",
      "Epoch 9/10, Loss: 1310891.3750, MAE: 1113.3749, R²: 0.4942\n",
      "Epoch 10/10, Loss: 2168229.7500, MAE: 767.9102, R²: 0.7810\n",
      "\n",
      "Subset 7\n",
      "Epoch 1/10, Loss: 12424427.0000, MAE: 1420.6542, R²: 0.5422\n",
      "Epoch 2/10, Loss: 10959172.0000, MAE: 1250.4265, R²: 0.6012\n",
      "Epoch 3/10, Loss: 5219215.0000, MAE: 1210.4266, R²: 0.6118\n",
      "Epoch 4/10, Loss: 715033.0000, MAE: 1222.0725, R²: 0.6090\n",
      "Epoch 5/10, Loss: 5740278.0000, MAE: 1182.7892, R²: 0.6148\n",
      "Epoch 6/10, Loss: 2264337.0000, MAE: 1151.8058, R²: 0.6182\n",
      "Epoch 7/10, Loss: 15758.4160, MAE: 1111.3950, R²: 0.6248\n",
      "Epoch 8/10, Loss: 3931222.5000, MAE: 1058.8146, R²: 0.6332\n",
      "Epoch 9/10, Loss: 3594137.5000, MAE: 1009.6416, R²: 0.6429\n",
      "Epoch 10/10, Loss: 2561726.7500, MAE: 1022.6074, R²: 0.6490\n",
      "\n",
      "Subset 8\n",
      "Epoch 1/10, Loss: 16784070.0000, MAE: 3715.2986, R²: -21.7780\n",
      "Epoch 2/10, Loss: 47891172.0000, MAE: 3600.7419, R²: -4.2081\n",
      "Epoch 3/10, Loss: 27296470.0000, MAE: 3477.7629, R²: -3.8492\n",
      "Epoch 4/10, Loss: 9676076.0000, MAE: 3327.6218, R²: -3.4516\n",
      "Epoch 5/10, Loss: 7043428.5000, MAE: 3165.7056, R²: -3.0243\n",
      "Epoch 6/10, Loss: 19834750.0000, MAE: 2978.2751, R²: -2.5685\n",
      "Epoch 7/10, Loss: 15063996.0000, MAE: 2775.5142, R²: -2.0958\n",
      "Epoch 8/10, Loss: 12601367.0000, MAE: 2549.2705, R²: -1.6144\n",
      "Epoch 9/10, Loss: 7835989.0000, MAE: 2309.6387, R²: -1.1435\n",
      "Epoch 10/10, Loss: 6265414.0000, MAE: 2054.5945, R²: -0.6936\n",
      "\n",
      "Subset 9\n",
      "Epoch 1/10, Loss: 4588.3115, MAE: 394.2746, R²: 0.9947\n",
      "Epoch 2/10, Loss: 10111.1182, MAE: 100.9846, R²: 0.9988\n",
      "Epoch 3/10, Loss: 7898.7847, MAE: 104.5438, R²: 0.9988\n",
      "Epoch 4/10, Loss: 2496.8882, MAE: 104.5869, R²: 0.9989\n",
      "Epoch 5/10, Loss: 5281.8301, MAE: 139.0732, R²: 0.9989\n",
      "Epoch 6/10, Loss: 38031.0039, MAE: 140.7260, R²: 0.9989\n",
      "Epoch 7/10, Loss: 13535.5879, MAE: 118.5358, R²: 0.9990\n",
      "Epoch 8/10, Loss: 2607276.0000, MAE: 115.8163, R²: 0.9991\n",
      "Epoch 9/10, Loss: 2369056.5000, MAE: 207.2340, R²: 0.9989\n",
      "Epoch 10/10, Loss: 5066.5962, MAE: 143.4661, R²: 0.9992\n",
      "\n",
      "Subset 10\n",
      "Epoch 1/10, Loss: 1677658.0000, MAE: 2260.1873, R²: 0.6322\n",
      "Epoch 2/10, Loss: 60610.4570, MAE: 521.6145, R²: 0.9907\n",
      "Epoch 3/10, Loss: 11610.1611, MAE: 147.9019, R²: 0.9992\n",
      "Epoch 4/10, Loss: 5707.7568, MAE: 56.1951, R²: 0.9999\n",
      "Epoch 5/10, Loss: 1165.4688, MAE: 49.0276, R²: 0.9999\n",
      "Epoch 6/10, Loss: 1257.4309, MAE: 54.1173, R²: 0.9999\n",
      "Epoch 7/10, Loss: 927.7184, MAE: 132.8652, R²: 0.9982\n",
      "Epoch 8/10, Loss: 12468319.0000, MAE: 1437.1056, R²: 0.9028\n",
      "Epoch 9/10, Loss: 690254.2500, MAE: 14545.8428, R²: -20.9504\n",
      "Epoch 10/10, Loss: 192213.7656, MAE: 1120.4238, R²: 0.8865\n"
     ]
    }
   ],
   "source": [
    " #Model 2\n",
    "model2 = StockNN(input_dim=X.shape[1])\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "subset_size = len(dataset) // 10\n",
    "subsets = [Subset(dataset, range(i*subset_size, (i+1)*subset_size)) for i in range(10)]\n",
    "\n",
    "for i, subset in enumerate(subsets):\n",
    "    print(f\"\\nSubset {i+1}\")\n",
    "    dataloader_subset = DataLoader(subset, batch_size=32, shuffle=True)\n",
    "    train_model(model2, dataloader_subset, optimizer2, criterion, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5370f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
